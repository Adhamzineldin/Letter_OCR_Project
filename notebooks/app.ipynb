{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Pipeline Runner and App Launcher\n",
    "\n",
    "This notebook lets you:\n",
    "\n",
    "1. **Run the training pipeline** to train the Decision Tree and Random Forest models on EMNIST letters.\n",
    "2. **Save trained models as artifacts** under `data/processed`.\n",
    "3. **Launch the Streamlit app** that uses those saved models for interactive exploration.\n",
    "\n",
    "> Tip: Run the cells from top to bottom. Make sure you have installed the dependencies in `requirments.txt` first.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T21:51:14.907874100Z",
     "start_time": "2025-12-14T21:51:14.895130100Z"
    }
   },
   "source": [
    "# Ensure the project root is on sys.path so imports work when running this notebook\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# When the notebook lives in `notebooks/`, the project root is its parent directory.\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "if (PROJECT_ROOT / \"src\").exists() and str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Python path updated with:\", PROJECT_ROOT / \"src\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\n",
      "Python path updated with: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\src\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T21:51:14.919308500Z",
     "start_time": "2025-12-14T21:51:14.908769900Z"
    }
   },
   "source": [
    "# Optional: verify config paths and that data directories exist\n",
    "from ocr_project import config\n",
    "\n",
    "print(\"EMNIST train:\", config.EMNIST_LETTERS_TRAIN)\n",
    "print(\"EMNIST test:\", config.EMNIST_LETTERS_TEST)\n",
    "print(\"Data dir:\", config.DATA_DIR)\n",
    "print(\"Processed dir:\", config.PROCESSED_DATA_DIR)\n",
    "\n",
    "# Ensure the key directories exist\n",
    "config.ensure_directories()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST train: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\data\\raw\\emnist-letters-train.csv\n",
      "EMNIST test: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\data\\raw\\emnist-letters-test.csv\n",
      "Data dir: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\data\n",
      "Processed dir: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\data\\processed\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:14:49.691137900Z",
     "start_time": "2025-12-14T21:51:14.924888200Z"
    }
   },
   "source": [
    "# Train three pipelines: pixels, HOG, and PCA, **plus** the new strong default.\n",
    "# Each saves its models into a separate artifacts folder so the app can\n",
    "# compare all combinations, and the default HOG+PCA pipeline saves to `artifacts`.\n",
    "# \n",
    "# NOTE: The pipeline now uses Cross-Validation on training data (5 folds) and\n",
    "# evaluates on a separate holdout test set.\n",
    "from ocr_project.pipeline import OCRPipeline, run_default_pipeline\n",
    "from ocr_project.features.hog_features import HOGFeatureExtractor\n",
    "from ocr_project.features.pca_features import PCAFeatures\n",
    "from ocr_project import config\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# 1) Pixels only (baseline)\n",
    "print(\"=== Pixels only (baseline) ===\")\n",
    "artifacts_pixels = config.PROJECT_ROOT / \"artifacts_pixels\"\n",
    "pipeline_pixels = OCRPipeline(artifacts_dir=artifacts_pixels)\n",
    "results_pixels = pipeline_pixels.run()\n",
    "for name, result in results_pixels.items():\n",
    "    if result.accuracy_std > 0:\n",
    "        print(f\"- {name}: CV = {result.accuracy:.4f} (±{result.accuracy_std:.4f}), Test = {result.test_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {name}: Test = {result.test_accuracy:.4f}\")\n",
    "all_results[\"pixels\"] = results_pixels\n",
    "\n",
    "# 2) HOG features\n",
    "print(\"\\n=== HOG features ===\")\n",
    "artifacts_hog = config.PROJECT_ROOT / \"artifacts_hog\"\n",
    "pipeline_hog = OCRPipeline(\n",
    "        feature_extractor=HOGFeatureExtractor(),\n",
    "        artifacts_dir=artifacts_hog,\n",
    ")\n",
    "results_hog = pipeline_hog.run()\n",
    "for name, result in results_hog.items():\n",
    "    if result.accuracy_std > 0:\n",
    "        print(f\"- {name}: CV = {result.accuracy:.4f} (±{result.accuracy_std:.4f}), Test = {result.test_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {name}: Test = {result.test_accuracy:.4f}\")\n",
    "all_results[\"hog\"] = results_hog\n",
    "\n",
    "# 3) PCA features\n",
    "print(\"\\n=== PCA features ===\")\n",
    "artifacts_pca = config.PROJECT_ROOT / \"artifacts_pca\"\n",
    "pipeline_pca = OCRPipeline(\n",
    "        feature_extractor=PCAFeatures(n_components=50),\n",
    "        artifacts_dir=artifacts_pca,\n",
    ")\n",
    "results_pca = pipeline_pca.run()\n",
    "for name, result in results_pca.items():\n",
    "    if result.accuracy_std > 0:\n",
    "        print(f\"- {name}: CV = {result.accuracy:.4f} (±{result.accuracy_std:.4f}), Test = {result.test_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {name}: Test = {result.test_accuracy:.4f}\")\n",
    "all_results[\"pca\"] = results_pca\n",
    "\n",
    "# 4) Strong default pipeline (HOG+PCA + powerful Random Forest) → saves to `artifacts`\n",
    "print(\"\\n=== Default HOG+PCA pipeline (artifacts/) ===\")\n",
    "default_results = run_default_pipeline()\n",
    "for name, result in default_results.items():\n",
    "    if result.accuracy_std > 0:\n",
    "        print(f\"- {name}: CV = {result.accuracy:.4f} (±{result.accuracy_std:.4f}), Test = {result.test_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {name}: Test = {result.test_accuracy:.4f}\")\n",
    "all_results[\"default_hog_pca\"] = default_results\n",
    "\n",
    "print(\"\\nTraining complete for all configurations.\")\n",
    "print(\"CV = Cross-Validation mean accuracy on training data\")\n",
    "print(\"Test = Accuracy on holdout test set (not used during training)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pixels only (baseline) ===\n",
      "Evaluating models using: Cross-Validation (on training data)\n",
      "Number of CV folds: 5\n",
      "Test data is kept as a separate holdout set.\n",
      "\n",
      "Training Decision Tree...\n",
      "  CV Mean Accuracy: 0.6817 (+/- 0.0037)\n",
      "  Test Set Accuracy: 0.6818\n",
      "\n",
      "Training Random Forest...\n",
      "  CV Mean Accuracy: 0.8716 (+/- 0.0027)\n",
      "  Test Set Accuracy: 0.8621\n",
      "- decision_tree: CV = 0.6817 (±0.0037), Test = 0.6818\n",
      "- random_forest: CV = 0.8716 (±0.0027), Test = 0.8621\n",
      "\n",
      "=== HOG features ===\n",
      "Evaluating models using: Cross-Validation (on training data)\n",
      "Number of CV folds: 5\n",
      "Test data is kept as a separate holdout set.\n",
      "\n",
      "Training Decision Tree...\n",
      "  CV Mean Accuracy: 0.6490 (+/- 0.0044)\n",
      "  Test Set Accuracy: 0.6286\n",
      "\n",
      "Training Random Forest...\n",
      "  CV Mean Accuracy: 0.8586 (+/- 0.0015)\n",
      "  Test Set Accuracy: 0.8426\n",
      "- decision_tree: CV = 0.6490 (±0.0044), Test = 0.6286\n",
      "- random_forest: CV = 0.8586 (±0.0015), Test = 0.8426\n",
      "\n",
      "=== PCA features ===\n",
      "Evaluating models using: Cross-Validation (on training data)\n",
      "Number of CV folds: 5\n",
      "Test data is kept as a separate holdout set.\n",
      "\n",
      "Training Decision Tree...\n",
      "  CV Mean Accuracy: 0.6147 (+/- 0.0029)\n",
      "  Test Set Accuracy: 0.6029\n",
      "\n",
      "Training Random Forest...\n",
      "  CV Mean Accuracy: 0.8417 (+/- 0.0026)\n",
      "  Test Set Accuracy: 0.8316\n",
      "- decision_tree: CV = 0.6147 (±0.0029), Test = 0.6029\n",
      "- random_forest: CV = 0.8417 (±0.0026), Test = 0.8316\n",
      "\n",
      "=== Default HOG+PCA pipeline (artifacts/) ===\n",
      "Evaluating models using: Cross-Validation (on training data)\n",
      "Number of CV folds: 5\n",
      "Test data is kept as a separate holdout set.\n",
      "\n",
      "Training Decision Tree...\n",
      "  CV Mean Accuracy: 0.6022 (+/- 0.0031)\n",
      "  Test Set Accuracy: 0.5934\n",
      "\n",
      "Training Random Forest...\n",
      "  CV Mean Accuracy: 0.8350 (+/- 0.0026)\n",
      "  Test Set Accuracy: 0.8250\n",
      "- decision_tree: CV = 0.6022 (±0.0031), Test = 0.5934\n",
      "- random_forest: CV = 0.8350 (±0.0026), Test = 0.8250\n",
      "\n",
      "Training complete for all configurations.\n",
      "CV = Cross-Validation mean accuracy on training data\n",
      "Test = Accuracy on holdout test set (not used during training)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:14:50.052579300Z",
     "start_time": "2025-12-14T22:14:50.006148200Z"
    }
   },
   "source": [
    "# Inspect saved artifacts used by the Streamlit app\n",
    "from pathlib import Path\n",
    "from ocr_project import config\n",
    "\n",
    "# The OCRPipeline now saves into a top-level \"artifacts\" directory so that\n",
    "# app.py can load models from there directly.\n",
    "artifacts_dir = config.PROJECT_ROOT / \"artifacts\"\n",
    "print(\"Artifacts saved under:\", artifacts_dir)\n",
    "\n",
    "for p in sorted(artifacts_dir.glob(\"*.pkl\")):\n",
    "    print(\"-\", p.name)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved under: G:\\University\\Third Year Term 1\\AI\\Letter_OCR_Project\\artifacts\n",
      "- decision_tree.pkl\n",
      "- random_forest.pkl\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the Streamlit app\n",
    "\n",
    "The following cell launches the Streamlit app defined in `app.py`.\n",
    "\n",
    "- **In Jupyter / VS Code / Cursor:** this will start Streamlit in a separate process.\n",
    "- Open the URL it prints (typically `http://localhost:8501`) in your browser.\n",
    "\n",
    "Stop the app with **Ctrl+C** in the terminal when you are done.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-12-14T22:14:50.066037300Z",
     "start_time": "2025-12-14T22:14:50.055582400Z"
    }
   },
   "source": [
    "# import sys\n",
    "# import subprocess\n",
    "# from pathlib import Path\n",
    "# \n",
    "# # Launch the Streamlit app from this notebook\n",
    "# # We run it with cwd set to the project root so that app.py and artifacts are found.\n",
    "# from ocr_project import config\n",
    "# project_root = config.PROJECT_ROOT\n",
    "# \n",
    "# cmd = [sys.executable, \"-m\", \"streamlit\", \"run\", \"app.py\"]\n",
    "# print(\"Running:\", \" \".join(cmd))\n",
    "# print(\"Working directory:\", project_root)\n",
    "# print(\"If nothing happens, open http://localhost:8501 manually in your browser.\")\n",
    "# \n",
    "# # Run Streamlit and capture its output so we can see why it exits\n",
    "# result = subprocess.run(cmd, cwd=str(project_root), capture_output=True, text=True)\n",
    "# \n",
    "# print(\"Return code:\", result.returncode)\n",
    "# print(\"\\n--- STDOUT ---\\n\")\n",
    "# print(result.stdout)\n",
    "# print(\"\\n--- STDERR ---\\n\")\n",
    "# print(result.stderr)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:14:50.076963300Z",
     "start_time": "2025-12-14T22:14:50.068042700Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:14:50.089528600Z",
     "start_time": "2025-12-14T22:14:50.079018100Z"
    }
   },
   "source": [
    "# import sys, subprocess\n",
    "# \n",
    "# print(\"Notebook Python:\", sys.executable)\n",
    "# subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"streamlit\"])"
   ],
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
